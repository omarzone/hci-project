# Metrics
### At first, metrics were only considered to evaluate the application's performance; however, after analyzing it carefully, we realized that user engagement is equally important. Therefore, we decided to implement metrics that relate to both. Some of the metrics we chose are:

### Transcription accuracy: 
This metric refers to the accuracy with which the AI can transcribe the user's spoken words into text. High accuracy is essential to ensure a smooth conversation and to avoid misunderstandings due to transcription errors.

### Response time: 
The time it takes for the AI to respond to the user's questions can affect the user experience and motivation to continue using the application. A fast response time is crucial for a satisfactory user experience.

### Success rate in overcoming anxiety: 
The main goal of the application is to help the user overcome their anxiety when speaking English. Therefore, an important metric would be to measure the user's success rate in overcoming their anxiety after using the application for a certain period of time.

### Number of grammar and pronunciation errors corrected: 
The application could also be evaluated based on its ability to detect and correct the user's grammar and pronunciation errors. A higher number of errors corrected indicates greater usefulness of the application.

### Total conversation time: 
Another useful metric for evaluating the application is the total time the user has spent talking to the AI. A longer total conversation time indicates greater user engagement and usefulness of the application.

### To achieve these metrics, we thought of several ways to measure them, including:

### Transcription accuracy: 
Transcription accuracy could be measured by comparing the text transcribed by the AI with the original text spoken by the user. One way to do this would be using the accuracy formula, which involves dividing the number of correctly transcribed words by the total number of words spoken and multiplying by 100 to obtain a percentage.

### Response time: 
Response time could be measured by recording the moment the user finishes speaking and the moment the AI begins to respond. The time elapsed between these events could then be calculated.

### Success rate in overcoming anxiety: 
The success rate could be measured through a survey conducted with users after a period of using the application. The survey could ask about the user's improvement in confidence when speaking English and the reduction in their anxiety. Subsequently, the success rate could be calculated using the survey results.

### Number of grammar and pronunciation errors corrected: 
The number of errors corrected could be measured by counting the total number of grammar and pronunciation errors detected by the AI and the number of errors the AI corrected correctly.

### Total conversation time: 
Total conversation time could be measured by simply adding up the time the user has spent talking to the AI during a certain period of time, such as a week or a month.
